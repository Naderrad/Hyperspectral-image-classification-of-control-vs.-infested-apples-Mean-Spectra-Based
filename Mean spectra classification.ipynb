{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # operations on numpy arrays\n",
    "import pandas as pd # dataframe\n",
    "import seaborn as sns # plotting\n",
    "import matplotlib.pyplot as plt # plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIR_FC10_CALYX_02_09_2021_mean.npy\n",
      "NIR_FC10_SIDE_02_09_2021_mean.npy\n",
      "NIR_FC10_STEM_02_09_2021_mean.npy\n",
      "NIR_FC11_CALYX_02_10_2021_mean.npy\n",
      "NIR_FC11_SIDE_02_10_2021_mean.npy\n",
      "NIR_FC11_STEM_02_10_2021_mean.npy\n",
      "NIR_FC12_CALYX_02_10_2021_mean.npy\n",
      "NIR_FC12_SIDE_02_10_2021_mean.npy\n",
      "NIR_FC12_STEM_02_10_2021_mean.npy\n",
      "NIR_FC13_CALYX_02_11_2021_mean.npy\n",
      "NIR_FC13_SIDE_02_11_2021_mean.npy\n",
      "NIR_FC13_STEM_02_11_2021_mean.npy\n",
      "NIR_FC15_CALYX_02_12_2021_mean.npy\n",
      "NIR_FC15_SIDE_02_12_2021_mean.npy\n",
      "NIR_FC15_STEM_02_12_2021_mean.npy\n",
      "NIR_FC17_CALYX_02_16_2021_mean.npy\n",
      "NIR_FC17_SIDE_02_16_2021_mean.npy\n",
      "NIR_FC18_CALYX_02_16_2021_mean.npy\n",
      "NIR_FC18_SIDE_02_16_2021_mean.npy\n",
      "NIR_FC1_CALYX_02_01_2021_mean.npy\n",
      "NIR_FC1_SIDE_02_01_2021_mean.npy\n",
      "NIR_FC1_STEM_02_01_2021_mean.npy\n",
      "NIR_FC20_CALYX_02_18_2021_mean.npy\n",
      "NIR_FC4_SIDE_02_04_2021_mean.npy\n",
      "NIR_FC5_CALYX_02_04_2021_mean.npy\n",
      "NIR_FC5_SIDE_02_04_2021_mean.npy\n",
      "NIR_FC5_STEM_02_04_2021_mean.npy\n",
      "NIR_FC6_CALYX_02_04_2021_mean.npy\n",
      "NIR_FC6_SIDE_02_04_2021_mean.npy\n",
      "NIR_FC6_STEM_02_04_2021_mean.npy\n",
      "NIR_FC7_CALYX_02_05_2021_mean.npy\n",
      "NIR_FC7_SIDE_02_05_2021_mean.npy\n",
      "NIR_FC7_STEM_02_05_2021_mean.npy\n",
      "NIR_FC8_CALYX_02_08_2021_mean.npy\n",
      "NIR_FC8_SIDE_02_08_2021_mean.npy\n",
      "NIR_FC8_STEM_02_08_2021_mean.npy\n",
      "NIR_FC9_CALYX_02_08_2021_mean.npy\n",
      "NIR_FC9_SIDE_02_08_2021_mean.npy\n",
      "NIR_FC9_STEM_02_08_2021_mean.npy\n",
      "NIR_FI13_CALYX_02_05_2021_mean.npy\n",
      "NIR_FI13_SIDE_02_05_2021_mean.npy\n",
      "NIR_FI13_STEM_02_05_2021_mean.npy\n",
      "NIR_FI14_CALYX_02_08_2021_mean.npy\n",
      "NIR_FI14_SIDE_02_08_2021_mean.npy\n",
      "NIR_FI14_STEM_02_08_2021_mean.npy\n",
      "NIR_FI15_CALYX_02_08_2021_mean.npy\n",
      "NIR_FI15_SIDE_02_08_2021_mean.npy\n",
      "NIR_FI15_STEM_02_08_2021_mean.npy\n",
      "NIR_FI16_CALYX_02_09_2021_mean.npy\n",
      "NIR_FI16_SIDE_02_06_2021_mean.npy\n",
      "NIR_FI16_STEM_02_09_2021_mean.npy\n",
      "NIR_FI17_CALYX_02_09_2021_mean.npy\n",
      "NIR_FI17_SIDE_02_09_2021_mean.npy\n",
      "NIR_FI17_STEM_02_09_2021_mean.npy\n",
      "NIR_FI19_CALYX_02_10_2021_mean.npy\n",
      "NIR_FI19_SIDE_02_10_2021_mean.npy\n",
      "NIR_FI19_STEM_02_10_2021_mean.npy\n",
      "NIR_FI21_CALYX_02_11_2021_mean.npy\n",
      "NIR_FI21_SIDE_02_11_2021_mean.npy\n",
      "NIR_FI21_STEM_02_11_2021_mean.npy\n",
      "NIR_FI23_CALYX_02_11_2021_mean.npy\n",
      "NIR_FI23_SIDE_02_11_2021_mean.npy\n",
      "NIR_FI23_STEM_02_11_2021_mean.npy\n",
      "NIR_FI25_CALYX_02_12_2021_mean.npy\n",
      "NIR_FI25_SIDE_02_12_2021_mean.npy\n",
      "NIR_FI25_STEM_02_12_2021_mean.npy\n",
      "NIR_FI31_CALYX_02_17_2021_mean.npy\n",
      "NIR_FI31_SIDE_02_17_2021_mean.npy\n",
      "NIR_FI31_STEM_02_17_2021_mean.npy\n",
      "NIR_FI32_CALYX_02_17_2021_mean.npy\n",
      "NIR_FI32_SIDE_02_17_2021_mean.npy\n",
      "NIR_FI32_STEM_02_17_2021_mean.npy\n",
      "NIR_FI34_CALYX_02_18_2021_mean.npy\n",
      "NIR_FI34_SIDE_02_18_2021_mean.npy\n",
      "NIR_FI34_STEM_02_18_2021_mean.npy\n",
      "NIR_FI35_CALYX_02_18_2021_mean.npy\n",
      "NIR_FI35_SIDE_02_18_2021_mean.npy\n",
      "NIR_FI35_STEM_02_18_2021_mean.npy\n",
      "NIR_FI37_CALYX_02_19_2021_mean.npy\n",
      "NIR_FI37_SIDE_02_19_2021_mean.npy\n",
      "NIR_FI37_STEM_02_19_2021_mean.npy\n",
      "NIR_FI40_CALYX_02_19_2021_mean.npy\n",
      "NIR_FI40_STEM_02_19_2021_mean.npy\n",
      "NIR_FI42_SIDE_02_19_2021_mean.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(84, 241)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the files in the destination folder to build the features of data set \n",
    "import os\n",
    "\n",
    "features = np.empty([1,241])\n",
    "directory = 'C:/Users/nek222/Desktop/PhD UKY/Data analysis/HSI/Mean spectra NIR from ROI Fuji whole apple/All orientations'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".npy\"): \n",
    "        #print(os.path.join(directory, filename))\n",
    "      arr = np.load(os.path.join(directory, filename))\n",
    "      arr_2d = np.reshape(arr, (1, 241))  \n",
    "      features  = np.append(features, arr_2d, axis=0) \n",
    "      print(filename)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "features = features[1:,:]\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral preprocessing using Savitzky-Golay filter\n",
    "from scipy.signal import savgol_filter\n",
    "features = savgol_filter(features, 31, polyorder=2, deriv=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral preprocessing using SNV\n",
    "def snv(input_data):          # Define a new array and populate it with the corrected data \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):            # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
    "    return output_data\n",
    "\n",
    "features = snv(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral preprocessing using Multiplicative scatter correction\n",
    "def msc(input_data):\n",
    "     \n",
    "     #mean centre correction\n",
    "    for i in range(input_data.shape[0]):\n",
    "        input_data[i,:] -= input_data[i,:].mean()\n",
    " \n",
    "     #Get the reference spectrum. If not given, estimate it from the mean    \n",
    "      \n",
    "        # Calculate mean\n",
    "    ref = np.mean(input_data, axis=0)\n",
    "    \n",
    " \n",
    "    # Define a new array and populate it with the corrected data    \n",
    "    data_msc = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    "        # Run regression\n",
    "        fit = np.polyfit(ref, input_data[i,:], 1, full=True)\n",
    "        # Apply correction\n",
    "        data_msc[i,:] = (input_data[i,:] - fit[0][1]) / fit[0][0] \n",
    " \n",
    "    return (data_msc)\n",
    "\n",
    "features = msc(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the labels of the data set\n",
    "from numpy import genfromtxt\n",
    "labels = genfromtxt('C:/Users/nek222/Desktop/PhD UKY/Data analysis/HSI/Mean spectra NIR from ROI Fuji whole apple/All orientations/Labels.csv', delimiter=',')\n",
    "#labels = np.load('C:/Users/nekra/OneDrive/Desktop/PhD UKY/Data analysis/HSI/NIR/Labels.npy') # Control and infested were marked by 0, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018972</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.018053</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.017133</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.016213</td>\n",
       "      <td>0.015753</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019596</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>0.018520</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0.017443</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018815</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.017444</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.015617</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.014703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018576</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>0.017295</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018838</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.017432</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>0.016495</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.015557</td>\n",
       "      <td>0.015089</td>\n",
       "      <td>0.014620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.018972  0.018512  0.018053  0.017593  0.017133  0.016673  0.016213   \n",
       "1  0.019596  0.019058  0.018520  0.017981  0.017443  0.016905  0.016367   \n",
       "2  0.018815  0.018358  0.017901  0.017444  0.016987  0.016530  0.016073   \n",
       "3  0.018576  0.018149  0.017722  0.017295  0.016868  0.016441  0.016014   \n",
       "4  0.018838  0.018370  0.017901  0.017432  0.016964  0.016495  0.016026   \n",
       "\n",
       "        7         8         9    ...       231       232       233       234  \\\n",
       "0  0.015753  0.015294  0.014834  ... -0.000125 -0.000067 -0.000010  0.000047   \n",
       "1  0.015828  0.015290  0.014752  ... -0.000177 -0.000115 -0.000053  0.000009   \n",
       "2  0.015617  0.015160  0.014703  ... -0.000174 -0.000103 -0.000032  0.000038   \n",
       "3  0.015587  0.015160  0.014733  ... -0.000182 -0.000119 -0.000057  0.000006   \n",
       "4  0.015557  0.015089  0.014620  ... -0.000215 -0.000136 -0.000058  0.000021   \n",
       "\n",
       "        235       236       237       238       239       240  \n",
       "0  0.000104  0.000161  0.000218  0.000275  0.000332  0.000389  \n",
       "1  0.000071  0.000133  0.000195  0.000257  0.000319  0.000381  \n",
       "2  0.000109  0.000180  0.000250  0.000321  0.000392  0.000463  \n",
       "3  0.000068  0.000131  0.000194  0.000256  0.000319  0.000381  \n",
       "4  0.000100  0.000178  0.000257  0.000335  0.000414  0.000493  \n",
       "\n",
       "[5 rows x 241 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert numpy array to pandas dataframe \n",
    "df = pd.DataFrame(features)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wavelength(nm)</th>\n",
       "      <th>Band</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900.1773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>903.5323</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>906.8871</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910.2417</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>913.5961</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1686.8290</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1690.1410</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1693.4520</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1696.7630</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1700.0740</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Wavelength(nm)  Band\n",
       "0          900.1773     1\n",
       "1          903.5323     2\n",
       "2          906.8871     3\n",
       "3          910.2417     4\n",
       "4          913.5961     5\n",
       "..              ...   ...\n",
       "236       1686.8290   237\n",
       "237       1690.1410   238\n",
       "238       1693.4520   239\n",
       "239       1696.7630   240\n",
       "240       1700.0740   241\n",
       "\n",
       "[241 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load wavelength info. each wavelength respond to 1 band\n",
    "df_wave = pd.read_csv('C:/Users/nek222/Desktop/PhD UKY/Data analysis/HSI/bands.csv')\n",
    "df_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Wavelength(nm)</th>\n",
       "      <th>900.1773</th>\n",
       "      <th>903.5323</th>\n",
       "      <th>906.8871</th>\n",
       "      <th>910.2417</th>\n",
       "      <th>913.5961</th>\n",
       "      <th>916.9503</th>\n",
       "      <th>920.3044</th>\n",
       "      <th>923.6582</th>\n",
       "      <th>927.0119</th>\n",
       "      <th>930.3654</th>\n",
       "      <th>...</th>\n",
       "      <th>1673.582</th>\n",
       "      <th>1676.894</th>\n",
       "      <th>1680.2060000000001</th>\n",
       "      <th>1683.5179999999998</th>\n",
       "      <th>1686.829</th>\n",
       "      <th>1690.141</th>\n",
       "      <th>1693.4520000000002</th>\n",
       "      <th>1696.763</th>\n",
       "      <th>1700.0739999999998</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018972</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.018053</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.017133</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.016213</td>\n",
       "      <td>0.015753</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019596</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>0.018520</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0.017443</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018815</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.017444</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.015617</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.014703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018576</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>0.017295</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018838</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.017432</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>0.016495</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.015557</td>\n",
       "      <td>0.015089</td>\n",
       "      <td>0.014620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Wavelength(nm)  900.1773  903.5323  906.8871  910.2417  913.5961  916.9503  \\\n",
       "0               0.018972  0.018512  0.018053  0.017593  0.017133  0.016673   \n",
       "1               0.019596  0.019058  0.018520  0.017981  0.017443  0.016905   \n",
       "2               0.018815  0.018358  0.017901  0.017444  0.016987  0.016530   \n",
       "3               0.018576  0.018149  0.017722  0.017295  0.016868  0.016441   \n",
       "4               0.018838  0.018370  0.017901  0.017432  0.016964  0.016495   \n",
       "\n",
       "Wavelength(nm)  920.3044  923.6582  927.0119  930.3654  ...  1673.582  \\\n",
       "0               0.016213  0.015753  0.015294  0.014834  ... -0.000067   \n",
       "1               0.016367  0.015828  0.015290  0.014752  ... -0.000115   \n",
       "2               0.016073  0.015617  0.015160  0.014703  ... -0.000103   \n",
       "3               0.016014  0.015587  0.015160  0.014733  ... -0.000119   \n",
       "4               0.016026  0.015557  0.015089  0.014620  ... -0.000136   \n",
       "\n",
       "Wavelength(nm)  1676.894  1680.2060000000001  1683.5179999999998  1686.829  \\\n",
       "0              -0.000010            0.000047            0.000104  0.000161   \n",
       "1              -0.000053            0.000009            0.000071  0.000133   \n",
       "2              -0.000032            0.000038            0.000109  0.000180   \n",
       "3              -0.000057            0.000006            0.000068  0.000131   \n",
       "4              -0.000058            0.000021            0.000100  0.000178   \n",
       "\n",
       "Wavelength(nm)  1690.141  1693.4520000000002  1696.763  1700.0739999999998  \\\n",
       "0               0.000218            0.000275  0.000332            0.000389   \n",
       "1               0.000195            0.000257  0.000319            0.000381   \n",
       "2               0.000250            0.000321  0.000392            0.000463   \n",
       "3               0.000194            0.000256  0.000319            0.000381   \n",
       "4               0.000257            0.000335  0.000414            0.000493   \n",
       "\n",
       "Wavelength(nm)  Label  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 242 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add label data to the dataframe and rename each column using the corresponding wavelength\n",
    "df.columns = df_wave['Wavelength(nm)']\n",
    "df['Label'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Wavelength(nm)</th>\n",
       "      <th>Reflectance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>900.177</td>\n",
       "      <td>0.018972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>900.177</td>\n",
       "      <td>0.019596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>900.177</td>\n",
       "      <td>0.018815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>900.177</td>\n",
       "      <td>0.018576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>900.177</td>\n",
       "      <td>0.018838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label Wavelength(nm)  Reflectance\n",
       "0    0.0        900.177     0.018972\n",
       "1    0.0        900.177     0.019596\n",
       "2    0.0        900.177     0.018815\n",
       "3    0.0        900.177     0.018576\n",
       "4    0.0        900.177     0.018838"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe transformation to match the input data format of lineplot function in seaborn \n",
    "df_melt = df.melt(id_vars='Label', value_name='Reflectance')\n",
    "df_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # import PCA class from scikit-learn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 10)\n",
      "variance explained by the first two PCs: 75.56%, 18.80%\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=10) # let's only consider the first n PCs\n",
    "pca_results = pca.fit_transform(features) # Fit the model with input and apply the dimensionality reduction on it.\n",
    "print(pca_results.shape)\n",
    "pca_scores = pca.explained_variance_ratio_ # variance explained by each component\n",
    "print('variance explained by the first two PCs: {:.2%}, {:.2%}'.format(*pca_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize first two components\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "s1, s2 = pca_results[:, 0], pca_results[:, 1]\n",
    "scatter = ax.scatter(s1, s2, c=labels, s=20, alpha=0.7)\n",
    "\n",
    "# create the legend\n",
    "hs, _ = scatter.legend_elements() # handlers of the legend\n",
    "ls = ['Control','Infested'] # labels of the legend\n",
    "ax.legend(hs, ls)\n",
    "\n",
    "# add labels\n",
    "ax.set_xlabel('PC1 (%.2f)'%pca_scores[0])\n",
    "ax.set_ylabel('PC2 (%.2f)'%pca_scores[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('pca.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import KFold # for five fold cross validation\n",
    "from sklearn.metrics import confusion_matrix # calcuate confusion matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overal accuracy: 0.824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.83      0.81      0.81        17\n",
      "weighted avg       0.82      0.82      0.82        17\n",
      "\n",
      "overal accuracy: 0.706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.67         7\n",
      "           1       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.70      0.71      0.70        17\n",
      "weighted avg       0.71      0.71      0.71        17\n",
      "\n",
      "overal accuracy: 0.529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.56        11\n",
      "           1       0.40      0.67      0.50         6\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.56      0.56      0.53        17\n",
      "weighted avg       0.60      0.53      0.54        17\n",
      "\n",
      "overal accuracy: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89         9\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.88      0.88      0.88        17\n",
      "weighted avg       0.88      0.88      0.88        17\n",
      "\n",
      "overal accuracy: 0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.80      0.57         5\n",
      "           1       0.86      0.55      0.67        11\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.65      0.67      0.62        16\n",
      "weighted avg       0.73      0.62      0.64        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "for train_index, test_index in kf.split(pca_results):\n",
    "    X_train, X_test = pca_results[train_index], pca_results[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    clf = LDA() \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    acc = (y_predict==y_test).sum()/len(y_test)\n",
    "    print('overal accuracy: %.3f'%acc)\n",
    "    cfx = confusion_matrix(y_test, y_predict, labels=[0,1])\n",
    "    print(classification_report(y_test, y_predict, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # for five fold cross validation\n",
    "from sklearn.metrics import confusion_matrix # calcuate confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overal accuracy: 0.701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.41      0.57        32\n",
      "           1       0.64      0.97      0.77        35\n",
      "\n",
      "    accuracy                           0.70        67\n",
      "   macro avg       0.79      0.69      0.67        67\n",
      "weighted avg       0.78      0.70      0.67        67\n",
      "\n",
      "overal accuracy: 0.731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.47      0.62        32\n",
      "           1       0.67      0.97      0.79        35\n",
      "\n",
      "    accuracy                           0.73        67\n",
      "   macro avg       0.80      0.72      0.71        67\n",
      "weighted avg       0.80      0.73      0.71        67\n",
      "\n",
      "overal accuracy: 0.746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.39      0.56        28\n",
      "           1       0.70      1.00      0.82        39\n",
      "\n",
      "    accuracy                           0.75        67\n",
      "   macro avg       0.85      0.70      0.69        67\n",
      "weighted avg       0.82      0.75      0.71        67\n",
      "\n",
      "overal accuracy: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.23      0.38        30\n",
      "           1       0.62      1.00      0.76        37\n",
      "\n",
      "    accuracy                           0.66        67\n",
      "   macro avg       0.81      0.62      0.57        67\n",
      "weighted avg       0.79      0.66      0.59        67\n",
      "\n",
      "overal accuracy: 0.721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.47      0.63        34\n",
      "           1       0.65      0.97      0.78        34\n",
      "\n",
      "    accuracy                           0.72        68\n",
      "   macro avg       0.79      0.72      0.70        68\n",
      "weighted avg       0.79      0.72      0.70        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "for train_index, test_index in kf.split(pca_results):\n",
    "    X_train, X_test = pca_results[train_index], pca_results[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly') # try linear kernel also\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_train)\n",
    "    acc = (y_predict==y_train).sum()/len(y_train)\n",
    "    print('overal accuracy: %.3f'%acc)\n",
    "    cfx = confusion_matrix(y_train, y_predict, labels=[0,1])\n",
    "    print(classification_report(y_train, y_predict, labels=[0, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overal accuracy: 0.706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71         7\n",
      "           1       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.73      0.73      0.71        17\n",
      "weighted avg       0.75      0.71      0.71        17\n",
      "\n",
      "overal accuracy: 0.588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59         7\n",
      "           1       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.61      0.61      0.59        17\n",
      "weighted avg       0.63      0.59      0.59        17\n",
      "\n",
      "overal accuracy: 0.529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.36      0.50        11\n",
      "           1       0.42      0.83      0.56         6\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.61      0.60      0.53        17\n",
      "weighted avg       0.66      0.53      0.52        17\n",
      "\n",
      "overal accuracy: 0.588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63         9\n",
      "           1       0.57      0.50      0.53         8\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.59      0.58      0.58        17\n",
      "weighted avg       0.59      0.59      0.59        17\n",
      "\n",
      "overal accuracy: 0.688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.80      0.62         5\n",
      "           1       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.69      0.72      0.68        16\n",
      "weighted avg       0.76      0.69      0.70        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "for train_index, test_index in kf.split(pca_results):\n",
    "    X_train, X_test = pca_results[train_index], pca_results[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    clf = KNN(n_neighbors=6) # default is 5\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    acc = (y_predict==y_test).sum()/len(y_test)\n",
    "    print('overal accuracy: %.3f'%acc)\n",
    "    cfx = confusion_matrix(y_test, y_predict, labels=[0,1])\n",
    "    print(classification_report(y_test, y_predict, labels=[0, 1]))\n",
    "    \n",
    "## plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overal accuracy: 0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.94        17\n",
      "   macro avg       0.95      0.93      0.94        17\n",
      "weighted avg       0.95      0.94      0.94        17\n",
      "\n",
      "overal accuracy: 0.647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.71      0.63         7\n",
      "           1       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.65      0.66      0.65        17\n",
      "weighted avg       0.67      0.65      0.65        17\n",
      "\n",
      "overal accuracy: 0.588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        11\n",
      "           1       0.46      1.00      0.63         6\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.73      0.68      0.58        17\n",
      "weighted avg       0.81      0.59      0.57        17\n",
      "\n",
      "overal accuracy: 0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.94        17\n",
      "   macro avg       0.94      0.94      0.94        17\n",
      "weighted avg       0.95      0.94      0.94        17\n",
      "\n",
      "overal accuracy: 0.812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77         5\n",
      "           1       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.81      0.86      0.81        16\n",
      "weighted avg       0.88      0.81      0.82        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "for train_index, test_index in kf.split(pca_results):\n",
    "    X_train, X_test = pca_results[train_index], pca_results[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    clf = RF() # try parameters: n_estimators=200, max_depth=5\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    acc = (y_predict==y_test).sum()/len(y_test)\n",
    "    print('overal accuracy: %.3f'%acc)\n",
    "    cfx = confusion_matrix(y_test, y_predict, labels=[0,1])\n",
    "    print(classification_report(y_test, y_predict, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overal accuracy: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83         7\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.92      0.86      0.87        17\n",
      "weighted avg       0.90      0.88      0.88        17\n",
      "\n",
      "overal accuracy: 0.706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62         7\n",
      "           1       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.70      0.69      0.69        17\n",
      "weighted avg       0.70      0.71      0.70        17\n",
      "\n",
      "overal accuracy: 0.588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        11\n",
      "           1       0.46      1.00      0.63         6\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.73      0.68      0.58        17\n",
      "weighted avg       0.81      0.59      0.57        17\n",
      "\n",
      "overal accuracy: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80         9\n",
      "           1       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.78      0.76      0.76        17\n",
      "weighted avg       0.78      0.76      0.76        17\n",
      "\n",
      "overal accuracy: 0.688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.55         5\n",
      "           1       0.80      0.73      0.76        11\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.65      0.66      0.65        16\n",
      "weighted avg       0.71      0.69      0.69        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# train and evaluate your model\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "for train_index, test_index in kf.split(pca_results):\n",
    "    X_train, X_test = pca_results[train_index], pca_results[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    clf = AdaBoostClassifier(n_estimators=1000, learning_rate=.6) # try parameters: n_estimators=200, max_depth=5\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    acc = (y_predict==y_test).sum()/len(y_test)\n",
    "    print('overal accuracy: %.3f'%acc)\n",
    "    cfx = confusion_matrix(y_test, y_predict, labels=[0,1])\n",
    "    print(classification_report(y_test, y_predict, labels=[0, 1]))\n",
    "# show the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import KFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import accuracy_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1] [1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=123)\n",
    "# Define the PLS object\n",
    "pls_binary = PLSRegression(n_components=10)\n",
    "# Fit the training set\n",
    "pls_binary.fit(X_train, y_train)\n",
    "# Predictions: these won't generally be integer numbers\n",
    "y_pred = pls_binary.predict(X_test)[:,0]\n",
    "# \"Force\" binary prediction by thresholding\n",
    "binary_prediction = (pls_binary.predict(X_test)[:,0] > 0.5).astype('uint8')\n",
    "print(binary_prediction, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pls_da(X_train,y_train, X_test):            # Define the PLS object for binary classification \n",
    "    plsda = PLSRegression(n_components=10)            # Fit the training set\n",
    "    plsda.fit(X_train, y_train)            # Binary prediction on the test set, done with thresholding\n",
    "    binary_prediction = (pls_binary.predict(X_test)[:,0] > 0.5).astype('uint8')\n",
    "    return binary_prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy on 5 splits:  0.8823529411764706\n",
      "Average accuracy on 5 splits:  0.8823529411764706\n",
      "Average accuracy on 5 splits:  0.8627450980392156\n",
      "Average accuracy on 5 splits:  0.8676470588235293\n",
      "Average accuracy on 5 splits:  0.8816176470588235\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "cval = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "for train, test in cval.split(features):\n",
    "    y_pred = pls_da(features[train,:], labels[train], features[test,:])\n",
    "    accuracy.append(accuracy_score(labels[test], y_pred))\n",
    "    print(\"Average accuracy on 5 splits: \", np.array(accuracy).mean())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overal accuracy: 0.824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.83      0.81      0.81        17\n",
      "weighted avg       0.82      0.82      0.82        17\n",
      "\n",
      "overal accuracy: 0.824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.83      0.81      0.81        17\n",
      "weighted avg       0.82      0.82      0.82        17\n",
      "\n",
      "overal accuracy: 0.706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74        11\n",
      "           1       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.72      0.73      0.70        17\n",
      "weighted avg       0.76      0.71      0.71        17\n",
      "\n",
      "overal accuracy: 0.824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.82         9\n",
      "           1       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.83      0.83      0.82        17\n",
      "weighted avg       0.83      0.82      0.82        17\n",
      "\n",
      "overal accuracy: 0.812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77         5\n",
      "           1       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.81      0.86      0.81        16\n",
      "weighted avg       0.88      0.81      0.82        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate your model\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    plsda = PLSRegression(n_components=10) \n",
    "    plsda.fit(X_train, y_train)\n",
    "    y_predict = plsda.predict(X_train)\n",
    "    binary_prediction = (plsda.predict(X_test)[:,0] > 0.5).astype('uint8')\n",
    "    acc = (binary_prediction==y_test).sum()/len(y_test)\n",
    "    print('overal accuracy: %.3f'%acc)\n",
    "    cfx = confusion_matrix(y_test, binary_prediction, labels=[0,1])\n",
    "    print(classification_report(y_test, binary_prediction, labels=[0, 1]))\n",
    "# show the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overal accuracy: 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        32\n",
      "           1       0.86      0.91      0.89        35\n",
      "\n",
      "    accuracy                           0.88        67\n",
      "   macro avg       0.88      0.88      0.88        67\n",
      "weighted avg       0.88      0.88      0.88        67\n",
      "\n",
      "overal accuracy: 0.910\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90        32\n",
      "           1       0.87      0.97      0.92        35\n",
      "\n",
      "    accuracy                           0.91        67\n",
      "   macro avg       0.92      0.91      0.91        67\n",
      "weighted avg       0.92      0.91      0.91        67\n",
      "\n",
      "overal accuracy: 0.910\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89        28\n",
      "           1       0.90      0.95      0.92        39\n",
      "\n",
      "    accuracy                           0.91        67\n",
      "   macro avg       0.91      0.90      0.91        67\n",
      "weighted avg       0.91      0.91      0.91        67\n",
      "\n",
      "overal accuracy: 0.910\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89        30\n",
      "           1       0.88      0.97      0.92        37\n",
      "\n",
      "    accuracy                           0.91        67\n",
      "   macro avg       0.92      0.90      0.91        67\n",
      "weighted avg       0.92      0.91      0.91        67\n",
      "\n",
      "overal accuracy: 0.956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96        34\n",
      "           1       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.96        68\n",
      "   macro avg       0.96      0.96      0.96        68\n",
      "weighted avg       0.96      0.96      0.96        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate your model\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    plsda = PLSRegression(n_components=10) \n",
    "    plsda.fit(X_train, y_train)\n",
    "    y_predict = plsda.predict(X_train)\n",
    "    binary_prediction = (plsda.predict(X_train)[:,0] > 0.5).astype('uint8')\n",
    "    acc = (binary_prediction==y_train).sum()/len(y_train)\n",
    "    print('overal accuracy: %.3f'%acc)\n",
    "    cfx = confusion_matrix(y_train, binary_prediction, labels=[0,1])\n",
    "    print(classification_report(y_train, binary_prediction, labels=[0, 1]))\n",
    "# show the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
